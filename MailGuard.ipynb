{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **MailGuard: Spam Detection System**\n",
        "\n",
        "\n",
        "*MailGuard is a spam email detection system built using machine learning models to classify emails as either spam or ham (legitimate). It leverages natural language processing (NLP) techniques, such as TF-IDF vectorization, and a variety of machine learning models, including Logistic Regression, Random Forest, and XGBoost. The project aims to provide an efficient and scalable solution for automatically classifying email messages.*\n",
        "\n"
      ],
      "metadata": {
        "id": "e-ZnALw_dX_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Spam Mail Detector**\n",
        "\n",
        "**Programming Language**\n",
        "* Python\n",
        "\n",
        "**Libraries and Frameworks**\n",
        "* Pandas: For data manipulation and analysis\n",
        "* NumPy: For numerical computations\n",
        "* Scikit-learn:\n",
        "  * train_test_split: For splitting data into training and testing sets.\n",
        "  * TfidfVectorizer: For feature extraction from text data.\n",
        "  * LogisticRegression, RandomForestClassifier: For machine learning models.\n",
        "  * GridSearchCV: For hyperparameter tuning.\n",
        "  * accuracy_score, classification_report, confusion_matrix: For model evaluation.\n",
        "* XGBoost: A high-performance machine learning model used for classification tasks.\n",
        "* re (Regular Expressions): For preprocessing and cleaning email data.\n",
        "\n",
        "**Machine Learning Algorithms**\n",
        "* Logistic Regression: A simple linear model for binary classification (ham or spam).\n",
        "* Random Forest Classifier: An ensemble learning method that can handle complex relationships in data.\n",
        "* XGBoost Classifier: A powerful boosting algorithm for high performance, often used in Kaggle competitions for classification tasks.\n",
        "\n",
        "**Data Processing and Feature Engineering**\n",
        "* TF-IDF Vectorization: Converts raw email text into numerical feature vectors using Term Frequency-Inverse Document Frequency (TF-IDF), with the option for n-grams (unigrams and bigrams) to capture word pairs.\n",
        "\n",
        "**Hyperparameter Tuning**\n",
        "* GridSearchCV: For tuning the hyperparameters of models like XGBoost to get the best results.\n",
        "\n",
        "**Data Storage**\n",
        "* CSV Files: Data is stored in CSV files (e.g., mail_data.csv), which is loaded and processed using Pandas.\n",
        "\n",
        "**Evaluation Metrics**\n",
        "* Accuracy: Measures the percentage of correct predictions (spam vs. ham).\n",
        "* Classification Report: Provides precision, recall, and F1-score for each class (spam/ham).\n",
        "* Confusion Matrix: Helps visualize the performance of classification models.\n",
        "\n",
        "**Environment**\n",
        "* Jupyter Notebook or IDE (like VS code or PyCharm):  For developing and testing your models interactively.\n",
        "* Google Colab: If you're working on a cloud-based environment for easy access to resources."
      ],
      "metadata": {
        "id": "3Fj8pYkvm0TN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing the Libraries**"
      ],
      "metadata": {
        "id": "H5vmSpr3YisI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import re"
      ],
      "metadata": {
        "id": "5-VyaQwGYPE1"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Loading and Preprocessing**"
      ],
      "metadata": {
        "id": "yq4QrETTYl01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_data(file_path):\n",
        "    raw_mail_data = pd.read_csv(file_path)\n",
        "    mail_data = raw_mail_data.fillna('')\n",
        "    mail_data['Category'] = mail_data['Category'].map({'spam': 0, 'ham': 1})\n",
        "    mail_data['Message'] = mail_data['Message'].apply(clean_text)\n",
        "    return mail_data\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b', '', text)\n",
        "    text = re.sub(r'\\W', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip().lower()\n",
        "\n",
        "file_path = '/content/mail_data.csv'\n",
        "mail_data = load_and_preprocess_data(file_path)\n",
        "\n",
        "X = mail_data['Message']\n",
        "Y = mail_data['Category']\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)\n"
      ],
      "metadata": {
        "id": "PuiKuYBYYR7d"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Future Engineering**"
      ],
      "metadata": {
        "id": "0qSnEwfcYu86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(X_train, X_test):\n",
        "    feature_extraction = TfidfVectorizer(ngram_range=(1, 2), min_df=5, stop_words='english', lowercase=True)\n",
        "    X_train_features = feature_extraction.fit_transform(X_train)\n",
        "    X_test_features = feature_extraction.transform(X_test)\n",
        "    return X_train_features, X_test_features, feature_extraction\n",
        "\n",
        "X_train_features, X_test_features, feature_extraction = extract_features(X_train, X_test)\n"
      ],
      "metadata": {
        "id": "AzOwRJwWYw0p"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Defination**"
      ],
      "metadata": {
        "id": "rjD2glIaY0kt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def define_models():\n",
        "    lr_model = LogisticRegression(class_weight='balanced', max_iter=200, random_state=42)\n",
        "    xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', scale_pos_weight=1.5, random_state=42)\n",
        "    rf_model = RandomForestClassifier(class_weight='balanced', n_estimators=100, random_state=42)\n",
        "\n",
        "    return {\n",
        "        \"Logistic Regression\": lr_model,\n",
        "        \"XGBoost\": xgb_model,\n",
        "        \"Random Forest\": rf_model\n",
        "    }\n",
        "\n",
        "models = define_models()\n"
      ],
      "metadata": {
        "id": "o7kRDg9wY22R"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter Tuning**"
      ],
      "metadata": {
        "id": "J3V1lB26Y6DF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tune_xgboost(X_train_features, Y_train):\n",
        "    param_grid = {\n",
        "        'learning_rate': [0.01, 0.1],\n",
        "        'max_depth': [3, 5],\n",
        "        'n_estimators': [100, 200]\n",
        "    }\n",
        "    grid_search = GridSearchCV(estimator=models[\"XGBoost\"], param_grid=param_grid, scoring='accuracy', cv=3, n_jobs=-1)\n",
        "    grid_search.fit(X_train_features, Y_train)\n",
        "    return grid_search.best_estimator_\n",
        "\n",
        "xgb_best_model = tune_xgboost(X_train_features, Y_train)\n",
        "models[\"XGBoost (Tuned)\"] = xgb_best_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWVbPxPRY9qr",
        "outputId": "6157482d-5ea4-4015-ffe9-da2438aaf706"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [23:53:55] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train and Evaluate Models**"
      ],
      "metadata": {
        "id": "dh_U9xRaY_zt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_models(models, X_train_features, Y_train, X_test_features, Y_test):\n",
        "    for model_name, model in models.items():\n",
        "        print(f\"\\nTraining {model_name}...\")\n",
        "        model.fit(X_train_features, Y_train)\n",
        "\n",
        "        train_predictions = model.predict(X_train_features)\n",
        "        test_predictions = model.predict(X_test_features)\n",
        "\n",
        "        train_accuracy = accuracy_score(Y_train, train_predictions)\n",
        "        test_accuracy = accuracy_score(Y_test, test_predictions)\n",
        "\n",
        "        print(f\"{model_name} - Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
        "        print(f\"{model_name} - Testing Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "        print(f\"{model_name} - Classification Report:\\n\", classification_report(Y_test, test_predictions, target_names=['Spam', 'Ham']))\n",
        "        print(f\"{model_name} - Confusion Matrix:\\n\", confusion_matrix(Y_test, test_predictions))\n",
        "\n",
        "train_and_evaluate_models(models, X_train_features, Y_train, X_test_features, Y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gcmSoNhZEFQ",
        "outputId": "b8e0d2c1-e483-4921-a69d-0699bf7cf163"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Logistic Regression...\n",
            "Logistic Regression - Training Accuracy: 99.04%\n",
            "Logistic Regression - Testing Accuracy: 97.04%\n",
            "Logistic Regression - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        Spam       0.90      0.88      0.89       149\n",
            "         Ham       0.98      0.98      0.98       966\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.94      0.93      0.94      1115\n",
            "weighted avg       0.97      0.97      0.97      1115\n",
            "\n",
            "Logistic Regression - Confusion Matrix:\n",
            " [[131  18]\n",
            " [ 15 951]]\n",
            "\n",
            "Training XGBoost...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [23:53:56] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost - Training Accuracy: 98.97%\n",
            "XGBoost - Testing Accuracy: 97.04%\n",
            "XGBoost - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        Spam       0.97      0.81      0.88       149\n",
            "         Ham       0.97      1.00      0.98       966\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.97      0.90      0.93      1115\n",
            "weighted avg       0.97      0.97      0.97      1115\n",
            "\n",
            "XGBoost - Confusion Matrix:\n",
            " [[120  29]\n",
            " [  4 962]]\n",
            "\n",
            "Training Random Forest...\n",
            "Random Forest - Training Accuracy: 99.87%\n",
            "Random Forest - Testing Accuracy: 97.58%\n",
            "Random Forest - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        Spam       0.98      0.83      0.90       149\n",
            "         Ham       0.97      1.00      0.99       966\n",
            "\n",
            "    accuracy                           0.98      1115\n",
            "   macro avg       0.98      0.92      0.94      1115\n",
            "weighted avg       0.98      0.98      0.97      1115\n",
            "\n",
            "Random Forest - Confusion Matrix:\n",
            " [[124  25]\n",
            " [  2 964]]\n",
            "\n",
            "Training XGBoost (Tuned)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [23:54:00] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost (Tuned) - Training Accuracy: 98.70%\n",
            "XGBoost (Tuned) - Testing Accuracy: 96.68%\n",
            "XGBoost (Tuned) - Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        Spam       0.98      0.77      0.86       149\n",
            "         Ham       0.96      1.00      0.98       966\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.97      0.88      0.92      1115\n",
            "weighted avg       0.97      0.97      0.97      1115\n",
            "\n",
            "XGBoost (Tuned) - Confusion Matrix:\n",
            " [[114  35]\n",
            " [  2 964]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Custom Input Prediction**"
      ],
      "metadata": {
        "id": "fFeoDPc9ZJOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_custom_input(models, input_mail, feature_extraction):\n",
        "    input_mail_cleaned = [clean_text(mail) for mail in input_mail]\n",
        "    input_mail_features = feature_extraction.transform(input_mail_cleaned)\n",
        "\n",
        "    print(\"\\nCustom Input Prediction:\")\n",
        "    for model_name, model in models.items():\n",
        "        prediction = model.predict(input_mail_features)\n",
        "        result = \"Ham mail\" if prediction[0] == 1 else \"Spam mail\"\n",
        "        print(f\"{model_name}: {result}\")\n",
        "\n",
        "input_mail = [\"Congratulations! You've won a $1000 gift card. Click here to claim now!\"]\n",
        "predict_custom_input(models, input_mail, feature_extraction)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jECJFXyZN-i",
        "outputId": "19248920-3502-4a52-b42b-3269c78aab7f"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Custom Input Prediction:\n",
            "Logistic Regression: Spam mail\n",
            "XGBoost: Spam mail\n",
            "Random Forest: Spam mail\n",
            "XGBoost (Tuned): Spam mail\n"
          ]
        }
      ]
    }
  ]
}